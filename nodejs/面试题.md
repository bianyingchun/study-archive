### koa-compose 实现

利用递归实现了 Promise 的链式执行，不管中间件中是同步还是异步都通过 Promise 转成异步链式执行。

```javascript
function compose(middleware) {
  return function (context, next) {
    // last called middleware #
    return dispatch(0);
    function dispatch(i) {
      // 执行当前第 i 个中间件
      let fn = middleware[i];
      // 所有的中间件执行完毕
      if (i === middleware.length) fn = next;
      if (!fn) return Promise.resolve();
      try {
        // 执行当前的中间件
        // 这里的fn 就是app.use(fn) 传入的函数
        return Promise.resolve(fn(context, dispatch.bind(null, i + 1)));
      } catch (err) {
        return Promise.reject(err);
      }
    }
  };
}
```

### 说说你对 koa2 中间件的理解

核心中间件机制洋葱模型
通过 use 注册中间件到数组中，然后从从外层开始往内执行，遇到 next()后进入下一个中间件，当所有中间件执行完毕后，开始返回，执行中间件中未执行的代码，整体流程就是递归处理。
调用 dispatch 函数，从第一个开始执行，当有 next 方法时创建一个 promise，等到下一个中间件执行结束后再执行后续代码，当第二个中间件也有 next 方法时，依然会创建一个新的 promise 等待下一个中间件的执行结果。

### exporess, koa2 中间件和 redux 中间件比较

实例创建： express 使用工厂方法, koa 是类

1. koa 实现的语法更高级，使用 ES6，支持 generator(async await)
2. koa 没有内置 router, 增加了 ctx 全局对象，整体代码更简洁，使用更方便。
3. koa 中间件的递归为 promise 形式，express 使用 next 尾递归, redux 的柯里化中间件形式，更简洁灵活，函数式编程体现的更明显, redux 以 dispatch 覆写的方式进行中间件增强

### koa2 的洋葱模型和 redux 中间件的洋葱模型一样吗

### redux compose 的大概实现,reduce 的妙用

```javascript
function compose(...funcs) {
  if (funcs.length === 0) {
    return (arg) => arg;
  }

  if (funcs.length === 1) {
    return funcs[0];
  }

  return funcs.reduce((a, b) => (...args) => a(b(...args)));
}
function applyMiddleware(...middlewares) {
  return (createStore) => (...args) => {
    const store = createStore(...args);

    let dispatch = () => {
      throw new Error(
        `Dispatching while constructing your middleware is not allowed. ` +
          `Other middleware would not be applied to this dispatch.`
      );
    };

    const middlewareAPI = {
      getState: store.getState,
      // 这里很关键，也很巧妙! 没有使用store.dispatch 而是用了一个 `dispatch` 变量，下面会被compose的dispatch覆盖，
      // 这样传入 middlware 的第一个参数中的 dispatch 即为覆盖后的dispatch,
      // 对于类似 redux-thunk 这样的中间件，内部会调用 'store.dispatch', 使得其同样会走一遍所有中间件
      dispatch: (...args) => dispatch(...args),
    };

    // 应用中间件的第一层参数, 为了给中间件暴露store的getState和dispatch方法
    const chain = middlewares.map((middleware) => middleware(middlewareAPI));

    // compose 带来的就是剥洋葱似的函数调用 compose(f, g, h) => (...args) => f(g(h(...args)))
    // redux 中间件的核心就是复写 dispatch
    // 把 store.dispatch 传递给第一个中间件
    // 每一个中间件都会返回一个新的 dispatch 传递给下一个中间件

    dispatch = compose(...chain)(store.dispatch);

    return {
      ...store,
      dispatch, // dispatch 覆盖
    };
  };
}
```

### express 的中间件实现机制

express 本质上就是一个中间件管理器，当进入到 app.handle 的时候就是对中间件进行执行的时候，所以，最关键的两个函数就是：

app.handle 尾递归调用中间件处理 req 和 res
app.use 添加中间件

全局维护一个 stack 数组用来存储所有中间件，app.use 的实现就很简单了，可以就是一行代码

```javascript
app.use = function (fn) {
  this.stack.push(fn);
};
```

express 的真正实现当然不会这么简单，它内置实现了路由功能，其中有 router, route, layer 三个关键的类，有了 router 就要对 path 进行分流，stack 中保存的是 layer 实例，app.use 方法实际调用的是 router 实例的 use 方法,
app.handle 即对 stack 数组进行处理

```javascript
app.handle = function (req, res, callback) {
  var stack = this.stack;
  var idx = 0;
  function next(err) {
    if (idx >= stack.length) {
      callback("err");
      return;
    }
    var mid = stack[idx++];
    mid(req, res, next);
  }
  next();
};
```

这里就是所谓的"尾递归调用"，next 方法不断的取出 stack 中的“中间件”函数进行调用，同时把 next 本身传递给“中间件”作为第三个参数，每个中间件约定的固定形式为 (req, res, next) => {}, 这样每个“中间件“函数中只要调用 next 方法即可传递调用下一个中间件。

之所以说是”尾递归“是因为递归函数的最后一条语句是调用函数本身，所以每一个中间件的最后一条语句需要是 next()才能形成”尾递归“，否则就是普通递归，”尾递归“相对于普通”递归“的好处在于节省内存空间，不会形成深度嵌套的函数调用栈。

### 对比一下 express,koa2

1. express 自身集成了路由，视图处理等功能，koa 本身不集成任何中间件，需要配合路由试图等中间件进行开发
2. 异步流程控制， express 采用 callback 来处理一步，koa1 采用 generatro ,koa2 采用 async/await 。
3. 错误处理，express 使用 callback 捕获异常，对于深层次的异常捕获不了， koa 使用 try catch ,可以更好的解决异常捕获。
4. 中间件机制， express 采用尾递归调用。koa 采用洋葱模型.
5. 和 express 只有 request 和 response 对象不同，koa 增加了一个 context 作为这次请求的上下文，作为中间件的第一个参数，同时 context 上挂载了 response, request 对象.

### koa2 中 ctx.set 的等价写法

ctx.response.set == ctx.set

context：Koa 封装的带有一些和请求与相应相关的方法和属性
request：Koa 封装的 req 对象，比如提了供原生没有的 host 属性。
response：Koa 封装的 res 对象，对返回的 bodyhook 了 getter 和 setter。
ctx.request.ctx === ctx
ctx.response.ctx === ctx
ctx.request.app === ctx.app
ctx.response.app === ctx.app
ctx.req === ctx.response.req
//==============分割线===========================

### node 作为中间层

客户端直接请求到中间层的 node,node 分析请求，看需要哪个页面，再去请求对应数据，拿到数据后和模板结合成用户看到的页面，返回给前端。

### node 作为中间层的优点

1.减轻客户端内存，不会像 mvvvm 把数据请求和页面渲染都压在客户端，而是在服务端完成 2. 更利于 seo 3. 保持了前后端分离的优点和目的，解放后端 4. 前端可操作的范围增多，甚至可以做服务器，数据库层面的优化，比如中间层常常用 nginx，redis 来优化项目,应对高并发

### node 的常用包

1. koa/expess 搭建服务器
2. multer 处理文件上传
3. crypto 加密
4. node-xlsx 读取 xlsx 表格文件
5. pac-proxy-agent 代理
6. jsonwebtoken 用于搭建 token 验证
7. xss 防止 xss 攻击

### 用 node 如何实现一个带压缩和缓存的 http-server？

### node 端处理大文件上传

### 上传文件的 content-type 是什么,node 如何拿到上传的文件内容(不利用插件)，文件内容是一次性传输过去的？

1. content-type: multipart/form-data
2. 如何拿到上传的文件内容

http 模块的 createServer(request, response),传入请求对象的 request 其实实现了 ReadableStream 接口，这个信息流可以被监听，或者与其他流进行对接。我们可以通过监听 data 和 end 事件，把数据给取出来

```javascript
const http = require("http");
let data = "";
http
  .createServer((request, response) => {
    request
      .on("error", (err) => {
        console.log(err);
      })
      .on("data", (chunk) => {
        data += chunk;
      })
      .on("end", () => {
        console.log(data);
      });
  })
  .listen(8080);
```

### 业务中看你有涉及到 node 的文件读写操作,有没有想过如果某个文件被锁怎么处理？

### 某些接口允许跨域,某些不允许,如何实现?能不能使用 koa2 中间件的方式实现一下?

1. koa2-cors

```javascript
const cors = require("koa2-cors");
// 跨域
app.use(
  cors({
    origin: function (ctx) {
      //设置允许来自指定域名请求
      return "*";
      // if (ctx.url === '/test') {
      //     return '*'; // 允许来自所有域名请求
      // }
      // return 'http://localhost:8080'; //只允许http://localhost:8080这个域名的请求
    },
    maxAge: 5, //指定本次预检请求的有效期，单位为秒。
    credentials: true, //是否允许发送Cookie
    allowMethods: ["GET", "POST", "PUT", "DELETE", "OPTIONS"], //设置所允许的HTTP请求方法
    allowHeaders: ["Content-Type", "Authorization", "Accept"], //设置服务器支持的所有头信息字段
    exposeHeaders: ["WWW-Authenticate", "Server-Authorization"], //设置获取其他自定义字段
  })
);
```

2. koa // todo

```javascript
app.use(async (ctx, next) => {
  if (
    ctx.request.header.origin !== ctx.origin &&
    whiteList.includes(ctx.request.header.origin) //检测白名单
  ) {
    ctx.set("Access-Control-Allow-Origin", ctx.request.header.origin);
    ctx.set("Access-Control-Allow-Credentials", true);
    //可选 指定浏览器CORS请求会额外发送的头信息字段
    ctx.set(
      "Access-Control-Allow-Headers",
      "Origin, X-Requested-With, Content-Type, Accept, Authorization"
    );
  }
  await next();
});

app.use(async (ctx, next) => {
  if (ctx.method === "OPTIONS") {
    //表明服务器支持的所有跨域请求的方法,而不单是浏览器请求的那个方法。这是为了避免多次"预检"请求。
    ctx.set("Access-Control-Allow-Methods", "PUT,DELETE,POST,GET");
    //该字段可选，用来指定本次预检请求的有效期，单位为秒。
    ctx.set("Access-Control-Max-Age", 3600 * 24);
    ctx.body = "";
  }
  await next();
});
//ctx.origin与ctx.request.header.origin不同，ctx.origin是本服务器的域名，ctx.request.header.origin是发送请求的请求头部的origin，二者不要混淆
```

[]()

### koa-body 原理

koa-body 中间件作用是将 post 请求的请求体携带的数据解析到 ctx.request.body 中，
原理是先用 type-is 这个包(ctx.is 函数，根据请求的 content-type)判断出请求的数据类型，然后根据不同的类型用 co-body(请求体解析)和 formidable(数据类型是 multipart,文件上传解析)来解析，拿到解析结果后放到 ctx.request.body 或者 ctx.request.files 里面。

### node 事件循环机制

[事件循环机制专题](./事件循环机制.md)

### 业务中的实时保存会有性能开销,又没有做什么优化？

开启多进程 ？

### 你觉得 node 的适用场景是什么

适合运用在高并发，io 密集，少量业务逻辑的场景。用户表单收集，聊天室，web 论坛。。
其实 nodej 能实现几乎一切的应用，但要考虑的是适不适合。

### node 的优缺点

1. 优点
   1. js 运行环境，js 也可以开发后端程序
   2. 事件驱动，通过单线程维护时间循环队列，没有多线程的资源占用，和上下文切换，高效扩展性好，能充分利用系统资源
   3. 非阻塞 io，能处理高并发
   4. 主线程为单线程
   5. 跨平台，可以用在 pc web，electron, 移动端，react-native
   6. 可以做请求转发，合并请求，削减 json 大小，可以独立可控制路由，可以独立部署上线
2. 缺点
   1. 不适合 cpu 密集型应用，由于 js 是单线程，如果长时间运行机选，会使 cpu 时间片得不到释放，后续 io 无法发起
      (解决方案：分解大型运算任务为多个小任务， 使得运算适时释放，不阻塞 io 的发起)
   2. 不适合大内存的应用
      v8 的内存管理机制限制(64 为 1.4G, 32 为 0.7G)
   3. 不适合大量同步的应用
   4. 只适合单核 cpu，不能充分利用 cpu
   5. 可靠性低，一旦某个环节崩溃，整个系统都崩溃
      原因：单线程
      解决：1. nginx 发现代理，负载均衡，开多个进程，绑定多个端口；2. 开启多个进程监听同一个端口，使用 cluster 模块

### node 的核心模块

1. http 模块 创建服务器
2. fs 模块 文件读写
3. path 操作文件路径
4. os 基本的操作系统相关的方法
   // CPU 的字节序

```javascript
// cpu 字节序
os.endianness();
// 操作系统名
os.type();
// 操作系统名
os.platform();
// 系统内存总量
os.totalmem();
// 操作系统空闲内存量
os.freemem();
// 返回一个对象数组，其中包含有关每个逻辑 CPU 内核的信息。
os.cpus();
```

5. **stream 模块**
   四种类型
1. readable
1. writeable
1. duplex 读写流
1. transform 转换流
   为什么要使用 stream
   减少 node 由于单线程读取大文件而导致其他程序停止。避免一次性读取所有文件内容再返回，
   stream 进行流处理数据时，传递的是 buffer 数据，最大的好处就是开辟的内存都是堆外内存，不管 v8 管理，在 c++层面实现内存的申请。

### node 单线程容易崩溃,怎么维护服务的

使用 pm2

### pm2 内部机制了解吗

PM2 模块是 cluster 模块的一个包装层。它的作用是尽量将 cluster 模块抽象掉，让用户像使用单进程一样，部署多进程 Node 应用。

### pm2 依据什么重启服务

采用心跳包检测查看子进程是否处于活跃状态
每隔数秒钟向子进程发送心跳包，子进程如果不会飞，那么调用 kill 杀死这个进程，然后再重启 cluster.fork()一个新的进程，子进程可以监听到错误事件，这时可以发送消息给主进程，要求杀死自己，并且主进程此时重新调用 cluster.fork()一个新的子进程。

### 使用 pm2 的好处

1. 进程守护，系统崩溃自动重启
2. 启动多进程，充分利用 cpu 和内存
3. 自带日志记录功能
4. pm2 官方也结合 pm2 管理提供了一套可视化在线监控平台 keymetrics 实时监控

### 为什么要使用 pm2

对于这个问题，先说说我的看法，最基本的原因是因为 node 本身是一个单线程应用，它的特点就是所有方法都是串行一次执行，并且 node 并没有能力像 Java 一样独自去创建一个新的线程来实现异步操作，如果在执行 I/O 中遇到了阻塞就会降低整个应用的执行效率，导致 CPU 使用率高等不利原因。

因此在这种模式下，一个线程只能处理一个任务，要想提高吞吐量必须通过多线程。虽然单线程的好处有很多比如避免了线程同步或者死锁、状态同步等等之类的问题，但是在应用和计算能力要求日益倍增的今天，单线程最大的弊端就是无法利用多核 CPU 带来的优势来提升运行效率。
同时为了弥补单线程无法利用多核 CPU 的问题，提供了“子进程”这个概念，Node.js 实际上是 Javascript 执行线程的单线程，真正的的 I/O 操作，底层 API 调用都是通过多线程执行的。

1. pm2 可以把你的应用部署到服务器所有的 CPU 上（$ pm2 start app.js -i max），有效的解决了之前背景里提出的问题。
2. 同样是进程管理器，为什么不用 forever？我认为最大的区别是在监控欠缺，进程和集群管理有限

### 不用 pm2 怎么做进程管理

1. cluster api ，在业务代码上起一个 master 进程，它 fork 出多个 worker 来处理任务，每当一个 worker 挂了，会有事件传回 master,master 就能重新 fork 一份新的 worker,只要 master 不挂，就能达到守护进程的目的.
2. node-forever 原理就是崩溃就从重启一个

### 主线程挂了，pm2 如何处理

PM2 的方式
PM2 内置了处理上述的逻辑，你不用再写这么多繁琐的代码了。
只需这样一行：
$ pm2 start app.js -i 4
-i <number of workers> 表示实例程序的个数。就是工作线程。
如果 i 为 0 表示，会根据当前 CPU 核心数创建 .

1. 保持你的程序不中断运行
   如果有任何工作线程意外挂掉了，PM2 会立即重启他们，当前你可以在任何时候重启
   pm2 restart all
2. 实时调整集群数量
   你可以使用命令 pm2 scale <app name> <n> 调整你的线程数量，
   如 pm2 scale app +3 会在当前基础上加 3 个工作线程。
3. 在生产环境让你的程序永不中断
   PM2 reload <app name> 命令会一个接一个的重启工作线程，在新的工作线程启动后才结束老的工作线程。
   这种方式可以保持你的 Node 程序始终是运行状态。即使在生产环境下部署了新的代码补丁

### cluster 了解多少

[详见 clurster 专题](./cluster.md)

### node 服务的性能监测有没有了解过?

### node 如何做错误监控，生成日志，日志等级

1. 使用 pm2 来部署程序，任何标准输出和标准错误输出都会被写入日志文件
2. log4js

### node 与 mysql 通信

1. mysql 库
2. 连接 mysql mysql.createConnect({...}).connect()
3. connection.query(sql, callback)

### 说一下锁,举例是读锁和写锁

它能保证一些方法在同一时间只能被执行一次, 从而避免并发问题.

1. 读写锁
   如果有其它线程读数据, 则允许其它线程执行读操作, 但不允许写操作
   如果有其它线程写数据, 则其它线程都不允许读和写操作
2. 互斥锁
   在大多数语言中, 互斥锁使用线程调度来实现的, 假如现在锁被锁住了, 那么后面的线程就会进入”休眠”状态, 直到解锁之后, 又会唤醒线程继续执行. 这也叫空等待(sleep-waiting).
3. 自旋锁
   自旋锁也是广义上的互斥锁, 是互斥锁的实现方式之一, 它不会产生线程的调度, 而是通过"循环"来尝试获取锁, 优点是能很快的获取锁, 缺点是会占用过多的 CPU 时间, 这被称为忙等待(busy-waiting).
4. 分布式锁
   在单机情况下, 在内存中的一个互斥锁就能控制到一个程序中所有线程的并发.
   但由于有集群架构(负载均衡/微服务等场景下), 内存中的锁就没用了. 所以我们需要一个"全局锁"去实现控制多个程序/多个机器上的线程并发. 这个全局锁就叫"分布式锁".

### 服务端渲染

简单理解是将组件或页面通过服务器生成 html 字符串，再发送到浏览器，最后将静态标记"混合"为客户端上完全交互的应用程序 (数据+模板)

##### 优点

1. 更利于 SEO。
2. 更利于首屏渲染
   首屏渲染是服务器发送过来的 html 字符串，并不依赖 js 文件，就会更快呈现页面内容，尤其针对大型单页应用，打包户文件体积较大，客户端渲染加载所有时间比较长，首页就会有很长的白屏等待时间

##### 缺点

1. 服务端压力较大
   本来是通过客户端完成渲染，现在统一到服务端 node 服务去做。尤其是高并发访问的情况，会大量占用服务端 CPU 资源；

2. 开发条件受限
   在服务端渲染中，只会执行到 componentDidMount 之前的生命周期钩子，因此项目引用的第三方的库也不可用其它生命周期钩子，这对引用库的选择产生了很大的限制；

3. 学习成本相对较高
   除了对 webpack、React 要熟悉，还需要掌握 node、Koa2 等相关技术。相对于客户端渲染，项目构建、部署过程更加复杂

#### 时间耗时比较

1. html 渲染
   服务端渲染是先向后端服务器请求数据，然后生成完整首屏 html 返回给浏览器；而客户端渲染是等 js 代码下载、加载、解析完成后再请求数据渲染，等待的过程页面是什么都没有的，就是用户看到的白屏。就是服务端渲染不需要等待 js 代码下载完成并请求数据，就可以返回一个已有完整数据的首屏页面。
2. 数据请求
   由服务端请求首屏数据，而不是客户端请求首屏数据，这是“快”的一个主要原因。服务端在内网进行请求，数据响应速度快。客户端在不同网络环境进行数据请求，且外网 http 请求开销大，导致时间差。

### 用 nodejs，将 base64 转化成 png 文件

```javascript
const filePath = "test.png";
const base64Data = imgData.replace(/^data:image\/\w+;base64,/, "");
const dataBuffer = Buffer.from(base64Data, "base64");
fs.writefileSync(filePath, dataBuffer);
```

### png 转成 base64

```javascript
const fs = require("fs");
const filePath = "test.png";
fs.readFile(filePath, (err, data) => {
  const imageBase64 = data.toString("base64");
  const imagePrefix = "data:image/png;base64,";
  console.log(imagePrefix + imageBase64);
});
```

### base 为什么能提升性能，缺点

[参考链接](imooc.com/article/27804#comment)
什么是 base64 编码?　　
图片的 base64 编码就是可以将一副图片数据编码成一串字符串，使用该字符串代替图像地址。
那么为什么要使用 base64 传输图片文件？
因为这样可以节省一个 http 请求。

缺点:

1. base64 会导致 css 文件变大，意味着 CRP 的阻塞。CRP（Critical Rendering Path，关键渲染路径）：当浏览器从服务器接收到一个 HTML 页面的请求时，到屏幕上渲染出来要经过很多个步骤。浏览器完成这一系列的运行，或者说渲染出来我们常常称之为“关键渲染路径”。

通俗而言，**就是图片不会导致关键渲染路径的阻塞，而转化为 Base64 的图片大大增加了 CSS 文件的体积，CSS 文件的体积直接影响渲染，导致用户会长时间注视空白屏幕**。HTML 和 CSS 会阻塞渲染，而图片不会。

2. 页面解析 CSS 生成的 CSSOM 时间增加
   Base64 跟 CSS 混在一起，大大增加了浏览器需要解析 CSS 树的耗时。其实解析 CSS 树的过程是很快的，一般在几十微妙到几毫秒之间。而如果 CSS 文件中混入了 Base64，那么（因为文件体积的大幅增长）解析时间会增长到十倍以上。

### node 模块查找策略

### node 转 buffer 输出字符串会比直接 string 输出快,你的依据是什么？

### node 的进程守护怎么做的,发现非预期故障怎么排查

，pm2 和 forever ，它们都可以实现进程守护，底层也都是通过上面讲的 child_process 模块和 cluster 模块 实现的

### 说一下进程线程,如何通信?

**IPC 的全称是 Inter-Process Communication,即进程间通信**。它的目的是为了让不同的进程能够互相访问资源并进行协调工作。**实现进程间通信的技术有很多，如命名管道，匿名管道，socket，信号量，共享内存，消息队列等**。Node 中实现 IPC 通道是依赖于 **libuv**。**windows 下由命名管道(name pipe)实现，linux 系统则采用 Unix Domain Socket 实现**。表现在应用层上的进程间通信只有简单的 message 事件和 send()方法，接口十分简洁和消息化。

父进程在实际创建子进程之前，会**创建 IPC 通道并监听它，然后才真正的创建出子进程**，这个过程中也会通过环境变量（NODE_CHANNEL_FD）告诉子进程这个**IPC 通道的文件描述符**。子进程在启动的过程中，根据文件描述符去连接这个已存在的 IPC 通道，从而完成父子进程之间的连接。

### 两个线程可以直接通信吗

1. 什么时候需要通信

- 多个线程并发执行时, 在默认情况下 CPU 是随机切换线程的
- 如果我们希望他们有规律的执行, 就可以使用通信, 例如每个线程执行一次打印

2. 怎么通信

- 如果希望线程等待, 就调用 wait()
- 如果希望唤醒等待的线程, 就调用 notify();
- 这两个方法必须在同步代码中执行, 并且使用同步锁对象来调用

### node 是真的单线程的吗？

Node 中最核心的是 v8 引擎，在 Node 启动后，会创建 v8 的实例，这个实例是多线程的。

- 主线程：编译、执行代码。
- 编译/优化线程：在主线程执行的时候，可以优化代码。
- 分析器线程：记录分析代码运行时间，为 Crankshaft 优化代码执行提供依据。
- 垃圾回收的几个线程。

所以大家常说的 Node 是单线程的指的是 JavaScript 的执行是单线程的(开发者编写的代码运行在单线程环境中)，但 Javascript 的宿主环境，无论是 Node 还是浏览器都是多线程的因为 libuv 中有线程池的概念存在的，libuv 会通过类似线程池的实现来模拟不同操作系统的异步调用，这对开发者来说是不可见的。

### nginx 负载均衡配置

### 业务线如何用端口号区分(nginx http-proxy)

### 看你简历有提到 nginx 配置,主要配置了什么

### 说下 jwt

### 知道 jwt 有哪些缺点吗

---

**模糊的知识点: process cluster stream buffer**
